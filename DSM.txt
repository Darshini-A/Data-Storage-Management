LinearDiscriminant  1st

import numpy as np
import pandas as pd
import plotly.express as px
from matplotlib import pyplot as plt
from sklearn import datasets
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

digits = load_digits()
digits

df = pd.DataFrame(digits.data, columns = digits.feature_names)
df

print("Target is : ", digits.target[0])
digits.data[0]

digits.data[0].reshape(8,8)

print("Target is : ", digits.target[0])
plt.gray()
plt.matshow(digits.data[0].reshape(8,8))
plt.show()

X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
lda = LinearDiscriminantAnalysis(n_components=9)
X_train = lda.fit_transform(X_train, y_train)
X_test = lda.transform(X_test)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

fig = px.scatter_3d(df, x=X_train[:,8], y=y_train, z=X_train[:,7],
                    labels={
                        "x": "LD1",
                        "y": "LD2",
                        "z": "LD3"
                        },
                    opacity=1, color = y_train)

fig.update_layout(scene=dict(xaxis_backgroundcolor="white",
                             yaxis_backgroundcolor="white",
                             zaxis_backgroundcolor="white"))

fig.update_layout(scene=dict(xaxis_showgrid=True, xaxis_gridwidth=1,
xaxis_gridcolor='lightgrey',
  xaxis_zeroline=True, xaxis_zerolinewidth=1,
xaxis_zerolinecolor='lightgrey',
  xaxis_showline=True, xaxis_linewidth=1, xaxis_linecolor='black',
  yaxis_showgrid=True, yaxis_gridwidth=1, yaxis_gridcolor='lightgrey',
  yaxis_zeroline=True, yaxis_zerolinewidth=1,
yaxis_zerolinecolor='lightgrey',
  yaxis_showline=True, yaxis_linewidth=1, yaxis_linecolor='black',
  zaxis_showgrid=True, zaxis_gridwidth=1, zaxis_gridcolor='lightgrey',
  zaxis_zeroline=True, zaxis_zerolinewidth=1,
zaxis_zerolinecolor='lightgrey',
  zaxis_showline=True, zaxis_linewidth=1, zaxis_linecolor='black'))

fig.update_layout(title_text="3D Linear Discriminant scatter plot")

fig.update_traces(marker=dict(size=3))
fig.show()



************************************************************************************



FashionMnistCNN  2nd

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

classes = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]
n=200
plt.imshow(x_train[n], cmap="gray")
plt.title(classes[y_train[n]])
plt.show()

y_train_ohe = to_categorical(y_train)
y_test_ohe = to_categorical(y_test)

x_train = x_train.reshape(60000, 28, 28, 1).astype("float")
x_test = x_test.reshape(10000, 28, 28, 1).astype("float")

model = Sequential()
model.add(Conv2D(filters=3, kernel_size=(3,3), strides=(1,1)))
model.add(Activation("relu"))
model.add(Flatten())
model.add(Dense(10, activation= "softmax"))
model.compile(optimizer="adam",
              loss="categorical_crossentropy",
              metrics="accuracy")
model.fit(x=x_train, y=y_train_ohe, epochs=15, validation_data=(x_test, y_test_ohe), batch_size=1000)



*********************************************************************************



CIFAR10CNN  3rd

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, MaxPool2D, Activation
     
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

y_train = y_train.flatten()
y_test = y_test.flatten()
classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
n=10000
plt.imshow(x_train[n])
plt.title(classes[y_train[n]])
plt.show()

y_train_ohe = to_categorical(y_train)
y_test_ohe = to_categorical(y_test)

x_train = x_train.reshape(50000, 32, 32, 3).astype("float")
x_test = x_test.reshape(10000, 32, 32, 3).astype("float")

model = Sequential()
model.add(Conv2D(filters = 4, kernel_size=(3,3), strides= (1,1), padding = "valid", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2)))
model.add(Flatten())
model.add(Dense(10, activation= "softmax"))
model.compile(optimizer="adam",
              loss="categorical_crossentropy",
              metrics="accuracy")
model.fit(x=x_train, y=y_train_ohe, epochs=5, validation_data=(x_test, y_test_ohe), batch_size=1000)



****************************************************************************************



PollutionTestCNN  4th

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import *
from sklearn.metrics import mean_squared_error as mse
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

test = pd.read_csv('/content/pollution_test_data.csv')
test.head()

target = test['pollution']
target.plot()

def wind_encode(s):
  if s == "SE":
    return 1
  elif s == "NE":
    return 2
  elif s == "NW":
    return 3
  else:
    return 4

test["wind_dir"] = test["wnd_dir"].apply(wind_encode)
test = test.drop(["wnd_dir"],  axis = 1).head()
test.head()

def df_to_X_y(df, window_size):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i : i+5]]
    X.append(row)
    label = df_as_np[i+5]
    y.append(label)
  return np.array(X), np.array(y)

WINDOW_SIZE = 6
X, y= df_to_X_y(target, WINDOW_SIZE)
X.shape, y.shape

X_train, y_train = X[:170], y[:170]
X_val, y_val = X[170:], y[170:340]

model = Sequential()
model.add(InputLayer((5,1)))
model.add(Conv1D(64, kernel_size=2))
model.add(Dense(8, 'relu'))
model.add(Dense(1, 'linear'))
model.summary()

cp = ModelCheckpoint('model/', save_best_only=True)
model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001),
metrics=[RootMeanSquaredError()])
model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=10, verbose=1,callbacks=[cp])



*****************************************************************************************



AirPollutionLSTM  5th

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error as mse
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

print('Imports Complete')

train = pd.read_csv('/content/LSTM-Multivariate_AirPollution.csv')
train.head()

train.shape

train.index = pd.to_datetime(train['date'], format = '%d-%m-%Y %H:%M')
poll = train['pollution']
poll.plot()

train.wnd_dir.unique()

def wind_encode(s):
  if s == "SE":
    return 1
  elif s == "NE":
    return 2
  elif s == "NW":
    return 3
  else:
    return 4

train["wind_dir"] = train["wnd_dir"].apply(wind_encode)
train = train.drop(["wnd_dir", 'date'], axis=1).head()
train.head()

def df_to_X_y(df, window_size):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i : i+5]]
    X.append(row)
    label = df_as_np[i+5]
    y.append(label)
  return np.array(X), np.array(y)

WINDOW_SIZE = 5
X, y = df_to_X_y(poll, WINDOW_SIZE)
X.shape, y.shape

X_train, y_train = X[:35000], y[:35000]
X_val, y_val = X[35000:], y[35000 : 65000]

model = Sequential()
model.add(InputLayer((5,1)))
model.add(LSTM(64))
model.add(Dense(8, 'relu'))
model.add(Dense(1, 'linear'))
model.summary()

cp = ModelCheckpoint('model/', save_best_only=True)
model.compile(loss = 'mse', optimizer = Adam(learning_rate=0.001), metrics = [RootMeanSquaredError()])
model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 10, verbose = 1, callbacks = [cp])

model = load_model('model/')
train_predictions = model.predict(X_train).flatten()
train_results = pd.DataFrame(data = {'Train Predictions': train_predictions, 'Actual':y_train})
train_results.head()

plt.plot(train_results['Train Predictions'][:50])
plt.plot(train_results['Actual'][:50])

val_predictions = model.predict(X_val).flatten()
val_results = pd.DataFrame(data = {'Val Predictions': val_predictions, 'Actual':y_val})
val_results.head()

plt.plot(val_results['Val Predictions'][:100])
plt.plot(val_results['Actual'][:100])

rmse = np.sqrt(mse(y_val, val_predictions))
print("Validation RMSE =", rmse)



*******************************************************************************



HeartAttack  6th

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.model_selection._split import train_test_split
from imblearn.combine import SMOTEENN
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

dataset = pd.read_csv('/content/heart.csv')
dataset.head()

X = dataset.iloc[:, :-1].values
Y = dataset.iloc[:, -1].values
for x, i in enumerate(Y):
  if i>0 : Y[x] = 1
dataset.info()

print(dataset.describe())

plt.bar(dataset['target'].unique(), dataset['target'].value_counts(), color = ['red', 'green'])
plt.xticks([0,1])
plt.xlabel('Heart Disease')
plt.ylabel('Count')
plt.title('Count of each Heart Disease')

histogram = dataset.hist()

imputer = SimpleImputer(missing_values=-9,strategy='mean')
imputer.fit(X[:, [6,7]])
X[:, [6,7]] = imputer.transform(X[:, [6,7]])
imputer = SimpleImputer(missing_values=-9, strategy='mean')
imputer.fit(X[:, [5,8]])
X[:, [5,8]] = imputer.transform(X[:, [5,8]])

smoteenn = SMOTEENN()
X_resampled, y_resampled = smoteenn.fit_resample(X, Y)
X_train, X_test, Y_Train, Y_Test = train_test_split(X_resampled, y_resampled, test_size=0.25)

new = train_test_split(X, Y, test_size=0.25)
X_test = new[1]
Y_Test = new[3]

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

DT = DecisionTreeClassifier(criterion='entropy', random_state=0)
DT.fit(X_train, Y_Train)
DT_Pred = DT.predict(X_test)
DTScore = accuracy_score(Y_Test, DT_Pred)
DT_precision_score = precision_score(Y_Test,DT_Pred)
DT_recall_score = recall_score(Y_Test,DT_Pred)
DT_Score = f1_score(Y_Test,DT_Pred)

print("Precision score =",DT_precision_score)
print("Recall score =", DT_recall_score)
print("F1 score =", DTScore)
print("Accuracy score of Decision Tree Algorithm =", DT_Score)



****************************************************************************************



StockPrediction  7th

import pandas as pd
import numpy as np
from datetime import datetime
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from plotly.graph_objs import Line

df = pd.read_pickle('/content/sample_data/SIEMENS-15minute-Hist.unknown')
df = pd.DataFrame(df)
df['date'] = df['date'].apply(pd.to_datetime)
df.set_index('date',inplace=True)
df.head()


fig = go.Figure(data = [go.Table(
    header=dict(values=list(['date', 'open', 'high', 'low', 'close', 'volume']),
                fill_color='lightblue',
                align='left'),
    cells=dict(values=[df.index, df.open, df.high, df.low, df.close, df.volume],
               fill_color='lavender',
               align='left'))
])
fig.show()

fig = make_subplots(rows=4, cols=1, subplot_titles=('Open', 'High', 'Low', 'Close'))

fig.add_trace(
    Line(x=df.index, y=df.open),
    row=1, col=1)
fig.add_trace(
    Line(x=df.index, y=df.high),
    row=2, col=1)
fig.add_trace(
    Line(x=df.index, y=df.low),
    row=3, col=1)
fig.add_trace(
    go.Line(x=df.index, y=df.close),
    row=4, col=1)

fig.update_layout(height=1400, width=1000, title_text="OHLC Line Plots")
fig.show()

result = seasonal_decompose(df.close.head(5000), model='additive', period = 30)
fig = go.Figure()
fig = result.plot()
fig.set_size_inches(20, 19)

open_data = [33.0, 33.3, 33.5, 33.0, 34.1]
high_data = [33.1, 33.3, 33.6, 33.2, 34.8]
low_data = [32.7, 32.7, 32.8, 32.6, 32.8]
close_data = [33.0, 32.9, 33.3, 33.1, 33.1]

dates = [datetime(year=2013, month=10, day=10),
         datetime(year=2013, month=11, day=10),
         datetime(year=2013, month=12, day=10),
         datetime(year=2014, month=1, day=10),
         datetime(year=2014, month=2, day=10)]


fig = go.Figure(data=[go.Candlestick(x=dates,
                                     open=open_data, high=high_data,
                                     low=low_data, close=close_data,
                                     increasing_line_color = 'green', decreasing_line_color= 'red')
])
fig.show()

fig = go.Figure(data=[go.Candlestick(x=df.index,
 open=df['open'],
 high=df['high'],
 low=df['low'],
 close=df['close'])])
fig.show()


new_df = pd.DataFrame()
new_df = df['close']
new_df.index = df.index

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
final_dataset = new_df.values
train_data = final_dataset[0:20000,]
valid_data = final_dataset[20000:,]
train_df = pd.DataFrame()
valid_df = pd.DataFrame()
train_df['Close'] = train_data
train_df.index = new_df[0:20000].index
valid_df['Close'] = valid_data
valid_df.index = new_df[20000:].index
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(final_dataset.reshape(-1,1))
x_train_data, y_train_data=[],[]
for i in range(60,len(train_data)):
    x_train_data.append(scaled_data[i-60:i,0])
    y_train_data.append(scaled_data[i,0])
x_train_data, y_train_data = np.array(x_train_data), np.array(y_train_data)
x_train_data = np.reshape(x_train_data, (x_train_data.shape[0], x_train_data.shape[1], 1))

lstm_model = Sequential()
lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train_data.shape[1], 1)))
lstm_model.add(LSTM(units=50))
lstm_model.add(Dense(1))

inputs_data = new_df[len(new_df)-len(valid_data)-60:].values
inputs_data = inputs_data.reshape(-1,1)
inputs_data = scaler.transform(inputs_data)

lstm_model.compile(loss='mean_squared_error', optimizer='adam')
lstm_model.summary()


X_test = []
for i in range(60, inputs_data.shape[0]):
 X_test.append(inputs_data[i-60:i,0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))
predicted_closing_price = lstm_model.predict(X_test)
predicted_closing_price = scaler.inverse_transform(predicted_closing_price)

valid_df['Predictions'] = predicted_closing_price
fig = go.Figure()
fig.add_trace(go.Scatter(x=train_df.index,y=train_df['Close'],
                         mode='lines',
                         name='Siemens Train Data'))
fig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Close'],
                         mode='lines',
                         name='Siemens Valid Data'))
fig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Predictions'],
                         mode='lines',
                         name='Prediction'))



**************************************************************************************



MnistMulticlassificationKeras  8th

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras.regularizers import L1L2
from tensorflow.keras.optimizers import Adadelta

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

x_train_flat = x_train.reshape(60000, 784)
x_test_flat = x_test.reshape(10000, 784)
y_train_ohe = to_categorical(y_train)
y_test_ohe = to_categorical(y_test)
print(x_train_flat.shape)
print(x_test_flat.shape)
print(y_train_ohe.shape)
print(y_test_ohe.shape)

print(y_train[210])
print(y_train_ohe[210])

print(y_train)
print(y_train.shape)

plt.imshow(x_train[0], cmap="gray")
plt.show()

model = Sequential()
model.add(Input(shape=(784,)))
model.add(Dense(units=100, activation="relu", kernel_regularizer=L1L2(l1=0, l2=0.5)))
model.add(Dense(units=10, activation = "softmax"))
model.compile(optimizer=Adadelta(learning_rate=0.05),
              loss="categorical_crossentropy",
              metrics="accuracy")
model.fit(x=x_train_flat, y=y_train_ohe, epochs=30, validation_data=(x_test_flat, y_test_ohe), batch_size=32)

history = model.history.history

train_loss= history["loss"]
val_loss= history["val_loss"]
plt.plot(train_loss)
plt.plot(val_loss)
plt.legend(["Train", "Validation"])
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.grid()
plt.show()

train_acc = history["accuracy"]
val_acc = history["val_accuracy"]
plt.plot(train_acc)
plt.plot(val_acc)
plt.ylim(0.5,1.1)
plt.legend(["Train", "Validation"])
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.grid()
plt.show()

model.summary()

plt.imshow(x_test[100], cmap="gray")
plt.show()

preds = model.predict(x_test_flat)

preds.shape

print(preds[100])
print(np.argmax(preds[100]))
